{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Previous Code from non-optimized model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Import our dependencies\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "#  Import and read the charity_data.csv.\r\n",
    "import pandas as pd \r\n",
    "application_df = pd.read_csv(\"charity_data.csv\")\r\n",
    "application_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimization Attempt 1: dropping columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\r\n",
    "application_df.drop(['EIN', 'NAME','APPLICATION_TYPE','CLASSIFICATION','STATUS'], axis=1, inplace=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Determine the number of unique values in each column.\r\n",
    "application_df.nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AFFILIATION                  6\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Generate our categorical variable lists\r\n",
    "application_cat = application_df.dtypes[application_df.dtypes == \"object\"].index.tolist()\r\n",
    "application_cat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['AFFILIATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Create a OneHotEncoder instance\r\n",
    "enc = OneHotEncoder(sparse=False)\r\n",
    "\r\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\r\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\r\n",
    "\r\n",
    "# Add the encoded variable names to the dataframe\r\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\r\n",
    "encode_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  USE_CASE_Preservation  ...  INCOME_AMT_1-9999  \\\n",
       "0             0.0                    0.0  ...                0.0   \n",
       "1             0.0                    1.0  ...                1.0   \n",
       "2             0.0                    0.0  ...                0.0   \n",
       "3             0.0                    1.0  ...                0.0   \n",
       "4             0.0                    0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Merge one-hot encoded features and drop the originals\r\n",
    "application_df = application_df.merge(encode_df, left_index=True,right_index=True)\r\n",
    "application_df = application_df.drop(columns = application_cat)\r\n",
    "application_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT  IS_SUCCESSFUL  AFFILIATION_CompanySponsored  \\\n",
       "0     5000              1                           0.0   \n",
       "1   108590              1                           0.0   \n",
       "2     5000              0                           1.0   \n",
       "3     6692              1                           1.0   \n",
       "4   142590              1                           0.0   \n",
       "\n",
       "   AFFILIATION_Family/Parent  AFFILIATION_Independent  AFFILIATION_National  \\\n",
       "0                        0.0                      1.0                   0.0   \n",
       "1                        0.0                      1.0                   0.0   \n",
       "2                        0.0                      0.0                   0.0   \n",
       "3                        0.0                      0.0                   0.0   \n",
       "4                        0.0                      1.0                   0.0   \n",
       "\n",
       "   AFFILIATION_Other  AFFILIATION_Regional  USE_CASE_CommunityServ  \\\n",
       "0                0.0                   0.0                     0.0   \n",
       "1                0.0                   0.0                     0.0   \n",
       "2                0.0                   0.0                     0.0   \n",
       "3                0.0                   0.0                     0.0   \n",
       "4                0.0                   0.0                     0.0   \n",
       "\n",
       "   USE_CASE_Heathcare  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                 0.0  ...                0.0                     0.0   \n",
       "1                 0.0  ...                1.0                     0.0   \n",
       "2                 0.0  ...                0.0                     0.0   \n",
       "3                 0.0  ...                0.0                     1.0   \n",
       "4                 1.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Determine the number of unique values in each column.\r\n",
    "application_df.nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ASK_AMT                         8747\n",
       "IS_SUCCESSFUL                      2\n",
       "AFFILIATION_CompanySponsored       2\n",
       "AFFILIATION_Family/Parent          2\n",
       "AFFILIATION_Independent            2\n",
       "AFFILIATION_National               2\n",
       "AFFILIATION_Other                  2\n",
       "AFFILIATION_Regional               2\n",
       "USE_CASE_CommunityServ             2\n",
       "USE_CASE_Heathcare                 2\n",
       "USE_CASE_Other                     2\n",
       "USE_CASE_Preservation              2\n",
       "USE_CASE_ProductDev                2\n",
       "ORGANIZATION_Association           2\n",
       "ORGANIZATION_Co-operative          2\n",
       "ORGANIZATION_Corporation           2\n",
       "ORGANIZATION_Trust                 2\n",
       "INCOME_AMT_0                       2\n",
       "INCOME_AMT_1-9999                  2\n",
       "INCOME_AMT_10000-24999             2\n",
       "INCOME_AMT_100000-499999           2\n",
       "INCOME_AMT_10M-50M                 2\n",
       "INCOME_AMT_1M-5M                   2\n",
       "INCOME_AMT_25000-99999             2\n",
       "INCOME_AMT_50M+                    2\n",
       "INCOME_AMT_5M-10M                  2\n",
       "SPECIAL_CONSIDERATIONS_N           2\n",
       "SPECIAL_CONSIDERATIONS_Y           2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Split our preprocessed data into our features and target arrays\r\n",
    "y = application_df['IS_SUCCESSFUL'].values\r\n",
    "X = application_df.drop(['IS_SUCCESSFUL'],1).values\r\n",
    "# Split the preprocessed data into a training and testing dataset\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Create a StandardScaler instances\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "# Fit the StandardScaler\r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Scale the data\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Attempt 1: Increase hidden layers from 2 to 3, with fewer columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\r\n",
    "number_input_features = len(X_train[0])\r\n",
    "hidden_nodes_layer1 = number_input_features*2.5\r\n",
    "hidden_nodes_layer2 = hidden_nodes_layer1/2\r\n",
    "hidden_nodes_layer3 = hidden_nodes_layer2\r\n",
    "\r\n",
    "\r\n",
    "nn1 = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "# First hidden layer\r\n",
    "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\r\n",
    "\r\n",
    "# Second hidden layer\r\n",
    "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\r\n",
    "\r\n",
    "# Third hidden layer\r\n",
    "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\r\n",
    "\r\n",
    "# Output layer\r\n",
    "nn1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\r\n",
    "\r\n",
    "# Check the structure of the model\r\n",
    "nn1.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 67)                1876      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 33)                2244      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 5,276\n",
      "Trainable params: 5,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Compile the model\r\n",
    "nn1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Add Checkpoints\r\n",
    "\r\n",
    "# Import checkpoint dependencies\r\n",
    "import os\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
    "\r\n",
    "# Define the checkpoint path and filenames\r\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\r\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\r\n",
    "\r\n",
    "# Create a callback that saves the model's weights every 5 epochs\r\n",
    "cp_callback = ModelCheckpoint(\r\n",
    "    filepath=checkpoint_path,\r\n",
    "    verbose=1,\r\n",
    "    save_weights_only=True,\r\n",
    "    save_freq=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Train the model\r\n",
    "fit_model = nn1.fit(X_train, y_train,epochs=30)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 36430.8008 - accuracy: 0.4965\n",
      "Epoch 2/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 10753.4082 - accuracy: 0.5015\n",
      "Epoch 3/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 6802.8818 - accuracy: 0.5019\n",
      "Epoch 4/30\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 7631.4336 - accuracy: 0.4977\n",
      "Epoch 5/30\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 3640.6624 - accuracy: 0.4962\n",
      "Epoch 6/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 1828.5389 - accuracy: 0.5147\n",
      "Epoch 7/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.6960 - accuracy: 0.5321\n",
      "Epoch 8/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
      "Epoch 9/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 10/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
      "Epoch 11/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
      "Epoch 12/30\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6912 - accuracy: 0.5321\n",
      "Epoch 13/30\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 14/30\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 15/30\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6911 - accuracy: 0.5321\n",
      "Epoch 16/30\n",
      "317/804 [==========>...................] - ETA: 0s - loss: 0.6913 - accuracy: 0.5303"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-995d8bfe3f7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1183\u001b[0m                 _r=1):\n\u001b[0;32m   1184\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    938\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3013\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3014\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3015\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3017\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1958\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1959\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1960\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Users\\Steven\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate the model using the test data\r\n",
    "model1_loss, model1_accuracy = nn1.evaluate(X_test_scaled,y_test,verbose=2)\r\n",
    "print(f\"Loss: {model1_loss}, Accuracy: {model1_accuracy}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Export our model to HDF5 file\r\n",
    "nn1.save(\"AlphabetSoupCharityAtt1.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attempt 2: Mix-up activation modes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\r\n",
    "number_input_features = len(X_train[0])\r\n",
    "hidden_nodes_layer1 = number_input_features*2.5\r\n",
    "hidden_nodes_layer2 = hidden_nodes_layer1/2\r\n",
    "\r\n",
    "\r\n",
    "nn2 = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "# First hidden layer\r\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\r\n",
    "\r\n",
    "# Second hidden layer\r\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\r\n",
    "\r\n",
    "# Output layer\r\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\r\n",
    "\r\n",
    "# Check the structure of the model\r\n",
    "nn2.summary()\r\n",
    "\r\n",
    "# Compile the model\r\n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "# Add Checkpoints\r\n",
    "# Define the checkpoint path and filenames\r\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\r\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\r\n",
    "\r\n",
    "# Create a callback that saves the model's weights every 5 epochs\r\n",
    "cp_callback = ModelCheckpoint(\r\n",
    "    filepath=checkpoint_path,\r\n",
    "    verbose=1,\r\n",
    "    save_weights_only=True,\r\n",
    "    save_freq=1000)\r\n",
    "# Train the model\r\n",
    "fit_model = nn2.fit(X_train, y_train,epochs=30)\r\n",
    "# Evaluate the model using the test data\r\n",
    "model2_loss, model2_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=2)\r\n",
    "print(f\"Loss: {model2_loss}, Accuracy: {model2_accuracy}\")\r\n",
    "# Export our model to HDF5 file\r\n",
    "nn2.save(\"AlphabetSoupCharityAtt2.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attempt 3: Mix-up activation Modes, use 3 hidden layers, add neurons, add epochs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\r\n",
    "number_input_features = len(X_train[0])\r\n",
    "hidden_nodes_layer1 = number_input_features*3\r\n",
    "hidden_nodes_layer2 = hidden_nodes_layer1/2\r\n",
    "hidden_nodes_layer3 = hidden_nodes_layer2\r\n",
    "\r\n",
    "nn3 = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "# First hidden layer\r\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\r\n",
    "\r\n",
    "# Second hidden layer\r\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"sigmoid\"))\r\n",
    "\r\n",
    "# Third hidden layer\r\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\r\n",
    "\r\n",
    "# Output layer\r\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\r\n",
    "\r\n",
    "# Check the structure of the model\r\n",
    "nn3.summary()\r\n",
    "\r\n",
    "# Compile the model\r\n",
    "nn3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "# Add Checkpoints\r\n",
    "# Define the checkpoint path and filenames\r\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\r\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\r\n",
    "\r\n",
    "# Create a callback that saves the model's weights every 5 epochs\r\n",
    "cp_callback = ModelCheckpoint(\r\n",
    "    filepath=checkpoint_path,\r\n",
    "    verbose=1,\r\n",
    "    save_weights_only=True,\r\n",
    "    save_freq=1000)\r\n",
    "# Train the model\r\n",
    "fit_model = nn3.fit(X_train, y_train,epochs=40)\r\n",
    "# Evaluate the model using the test data\r\n",
    "model3_loss, model3_accuracy = nn3.evaluate(X_test_scaled,y_test,verbose=2)\r\n",
    "print(f\"Loss: {model3_loss}, Accuracy: {model3_accuracy}\")\r\n",
    "# Export our model to HDF5 file\r\n",
    "nn3.save(\"AlphabetSoupCharityAtt3.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('mlenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "d97906487f17ddc14d94d7ddabb9c85cb07495ee85a23c81a01b25ca2382603b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}